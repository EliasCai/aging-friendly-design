# -*- coding: utf-8 -*-
"""
é¢å±…æ…§è§† â€“ ç²¾ç®€ä¸‰æ ç‰ˆï¼ˆæ¥å…¥ ModelScope å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼‰
å›¾åºŠå·²è¿ç§»è‡³ playground.z.wiki
"""
import os, io, hashlib, random, requests, gradio as gr
from PIL import Image, ImageDraw, ImageFont
from openai import OpenAI

# ----------- é…ç½® -----------
Z_TOKEN     = os.getenv('Z_TOKEN') or 'hellocgc@qq.com'   # ç¼ºçœæ–¹ä¾¿è°ƒè¯•
Z_API       = "https://playground.z.wiki/img/api/upload"
MS_TOKEN    = os.getenv('MS_TOKEN')
MS_API_URL  = "https://api-inference.modelscope.cn/v1"
PROMPT      = (
    "ä½ éœ€è¦ä»é€‚è€åŒ–æ”¹é€ çš„è§’åº¦å‡ºå‘ï¼Œæå‡º1-3ä¸ªæœ€é‡è¦çš„åˆç†å»ºè®®ï¼Œ\n"
    "è¦æ±‚ï¼š\n1. ä»…é™å®šä½ çœ‹åˆ°çš„ç”»é¢ï¼›\n"
    "2. ä½¿ç”¨ç›¸å¯¹ä½ç½®æè¿°ï¼Œå‹¿ç»™å‡ºç»å¯¹å°ºå¯¸ï¼›\n"
    "3. æ ¼å¼ä¸ºâ€œåºå·.æ”¹é€ å»ºè®®â€ã€‚\n"
)

# ----------- å·¥å…· -----------
def upload_image2z(pil_img: Image.Image) -> str:
    """PIL â†’ playground.z.wiki â†’ URL"""
    buf = io.BytesIO()
    pil_img.convert('RGB').save(buf, format='JPEG', quality=90)
    buf.seek(0)
    files = {'file': ('upload.jpg', buf, 'image/jpeg')}
    data  = {'uid': Z_TOKEN, 'fileName': 'upload.jpg'}
    rsp = requests.post(Z_API, files=files, data=data, timeout=30)
    rsp.raise_for_status()
    return rsp.json()['url']

def fake_annotated(pil_img: Image.Image) -> Image.Image:
    """éšæ‰‹ç”»çº¢æ¡†ç¤ºæ„"""
    W, H = pil_img.size
    img = pil_img.copy()
    draw = ImageDraw.Draw(img)
    font = ImageFont.load_default()
    for _ in range(random.randint(1, 3)):
        x1 = random.randint(0, W//2)
        y1 = random.randint(0, H//2)
        x2 = x1 + random.randint(80, 200)
        y2 = y1 + random.randint(80, 200)
        draw.rectangle([x1, y1, x2, y2], outline='red', width=6)
    draw.rectangle([0, H-80, W, H], fill='black')
    draw.text((20, H-60), 'AI æ”¹é€ ç¤ºæ„ï¼šå·²æ ‡æ³¨é£é™©ç‚¹', fill='white', font=font)
    return img

# ----------- æµå¼è°ƒç”¨ -----------
def stream_advise(image_url: str):
    client = OpenAI(base_url=MS_API_URL, api_key=MS_TOKEN)
    response = client.chat.completions.create(
        model='Qwen/Qwen3-VL-235B-A22B-Instruct',
        messages=[{
            'role': 'user',
            'content': [{'type': 'text', 'text': PROMPT},
                        {'type': 'image_url', 'image_url': {'url': image_url}}]
        }],
        stream=True)
    for chk in response:
        if chk.choices[0].delta.content:
            yield chk.choices[0].delta.content

# ----------- ç¼“å­˜ -----------
_cache = {}   # md5 â†’ url

def ai_advise(image):
    if image is None:
        yield 'è¯·å…ˆä¸Šä¼ ä¸€å¼ ç…§ç‰‡', None
        return
    after = fake_annotated(image)
    yield '', after

    key = hashlib.md5(image.tobytes()).hexdigest()
    url = _cache.get(key)
    if not url:
        try:
            url = upload_image2z(image)
            _cache[key] = url
        except Exception as e:
            yield f'ï¼ˆå›¾ç‰‡ä¸Šä¼ å¤±è´¥ï¼š{e}ï¼‰', after
            return

    buffer = ''
    for piece in stream_advise(url):
        buffer += piece
        yield buffer, after

# ----------- Chatbot -----------
def fake_chat(history, msg):
    history = history or []
    ans = random.choice([
        'æ‚¨å¯ä»¥è€ƒè™‘å®‰è£…æ„Ÿåº”å¤œç¯ï¼Œå‡å°‘èµ·å¤œè·Œå€’é£é™©ã€‚',
        'å®¶å…·åœ†è§’å¤„ç†æˆ–åŠ è£…é˜²æ’æ¡ï¼Œä¹Ÿæ˜¯ä½æˆæœ¬çš„å¥½æ–¹æ³•ã€‚',
        'å¦‚éœ€è¿›ä¸€æ­¥å¸®åŠ©ï¼Œå¯å’¨è¯¢æœ¬åœ°ç¤¾åŒºå…»è€æœåŠ¡ä¸­å¿ƒã€‚'])
    history.append([msg, ans])
    return history

# ----------- Gradio UI -----------
css = """
body{background:#fafafa;}
.gr-button-primary{font-size:20px!important;padding:12px 24px!important;background:#d60000!important;color:white!important;}
.gr-text-output,.gr-chatbot{font-size:22px!important;line-height:1.8!important;color:#222!important;}
.gr-markdown{font-size:26px!important;font-weight:bold!important;text-align:center!important;margin-bottom:10px!important;}
"""

with gr.Blocks(css=css, title='é¢å±…æ…§è§†') as demo:
    gr.Markdown('ğŸ  é¢å±…æ…§è§† Â· è®© AI å¸®çˆ¸å¦ˆæŠŠå®¶å˜å¾—æ›´å®‰å…¨')

    with gr.Tab('ğŸ“¸ ç¯å¢ƒè¯„ä¼°'):
        with gr.Row():
            with gr.Column():
                img_in  = gr.Image(label='1. æ‹æ‘„æˆ–ä¸Šä¼ ç…§ç‰‡', type='pil')
                btn     = gr.Button('ä¸€é”®è¯„ä¼°', elem_classes='gr-button-primary')
            with gr.Column():
                adv_out = gr.Textbox(label='2. AI è¯„ä¼°å»ºè®®', lines=4, elem_classes='gr-text-output', interactive=False)
                img_out = gr.Image(label='3. AI æ”¹é€ åç¤ºæ„å›¾', type='pil')
        btn.click(ai_advise, inputs=img_in, outputs=[adv_out, img_out])

    with gr.Tab('ğŸ’¬ è¿›ä¸€æ­¥å’¨è¯¢'):
        chat = gr.Chatbot(label='é€‚è€æ”¹é€ å°åŠ©æ‰‹', elem_classes='gr-chatbot', height=400)
        msg  = gr.Textbox(label='è¾“å…¥æ‚¨çš„é—®é¢˜', placeholder='ä¾‹å¦‚ï¼šæµ´å®¤é˜²æ»‘è¿˜æœ‰å“ªäº›ä¾¿å®œæ–¹æ¡ˆï¼Ÿ')
        send = gr.Button('å‘é€', elem_classes='gr-button-primary')
        send.click(fake_chat, inputs=[chat, msg], outputs=chat)
        msg.submit(fake_chat, inputs=[chat, msg], outputs=chat)

    with gr.Tab('ğŸ“– å‚è€ƒä¹¦ç±'):
        gallery = gr.Gallery(label='PDF é¢„è§ˆ', columns=2, height=700)

demo.queue().launch(server_name='0.0.0.0', debug=True, show_api=False)
