# -*- coding: utf-8 -*-
"""
é¢å±…æ…§è§† â€“ ç²¾ç®€ä¸‰æ ç‰ˆï¼ˆModelScope + DashScope å›¾åƒç¼–è¾‘ï¼‰
"""
import os, io, hashlib, requests, gradio as gr
from PIL import Image
from openai import OpenAI
import fitz  # PyMuPDF
import random
from typing import Iterator
from gradio import ChatMessage




# ------------------ é…ç½® ------------------
Z_TOKEN    = os.getenv('Z_TOKEN') 
Z_API      = "https://playground.z.wiki/img/api/upload"
MS_TOKEN   = os.getenv('MS_TOKEN') 
MS_API_URL = "https://api-inference.modelscope.cn/v1"
DS_KEY     = os.getenv('DASHSCOPE_API_KEY') 
PDF_PATH = r"./P020240613034653.pdf"  # è¯·æ¢æˆçœŸå®è·¯å¾„

PROMPT = (
    "ä½ éœ€è¦ä»é€‚è€åŒ–æ”¹é€ çš„è§’åº¦å‡ºå‘ï¼Œæå‡º1-5ä¸ªæœ€é‡è¦çš„åˆç†å»ºè®®ï¼Œ\n"
    "è¦æ±‚ï¼š\n1. ä»…é™å®šä½ çœ‹åˆ°çš„ç”»é¢ï¼›\n"
    "2. ä½¿ç”¨ç›¸å¯¹ä½ç½®æè¿°ï¼Œå‹¿ç»™å‡ºç»å¯¹å°ºå¯¸ï¼›\n"
    "3. æ ¼å¼ä¸ºâ€œåºå·.æ”¹é€ å»ºè®®â€ã€‚"
    "å‚è€ƒè¾“å‡ºï¼š"
    "1. åœ¨é©¬æ¡¶å·¦ä¾§å¢™é¢åŠ è£…Lå‹æ‰¶æ‰‹"
    "2. åœ¨æ·‹æµ´å–·å¤´ä¸‹æ–¹çš„å¢™é¢åŠ è£…å‚ç›´æ‰¶æ‰‹ï¼Œæä¾›æ·‹æµ´æ—¶çš„æ”¯æ’‘ç‚¹"
    "3. åœ¨åœ°é¢å¯è§åŒºåŸŸé“ºè®¾é˜²æ»‘è´´ï¼Œé˜²æ­¢æ»‘å€’"
    "4. åœ¨é©¬æ¡¶åæ–¹å¢™é¢å®‰è£…ç´§æ€¥å‘¼æ•‘æ‹‰ç»³è£…ç½®ï¼Œä¾¿äºçªå‘æƒ…å†µæ±‚åŠ©"
    "5. æ›´æ¢æ·‹æµ´çš„æ†ä»¶ä¸ºå¯ä¸Šä¸‹æ»‘åŠ¨çš„ç»æµå‹æ†ä»¶ï¼Œä½ç½®åœ¨æ·‹æµ´å–·å¤´çš„æ†ä»¶å¤„ã€‚"
)

PROMPT_ASK = \
"""
# é€‚è€å®œå±…è®¾è®¡æŒ‡å—

éšç€å¹´é¾„å¢é•¿ï¼Œè€å¹´äººå±…å®¶ç”Ÿæ´»ä¸­é¢ä¸´è¯¸å¤šå®‰å…¨éšæ‚£ï¼Œå¦‚åœ°é¢æ¹¿æ»‘ã€å…‰çº¿ä¸è¶³ã€æ“ä½œå¤æ‚ç­‰ã€‚æœ¬æŒ‡å—åŸºäºã€Šå®¶å±…äº§å“é€‚è€åŒ–è®¾è®¡æŒ‡å—ã€‹æ ¸å¿ƒå†…å®¹ï¼Œæç‚¼å‡ºé€‚ç”¨äºæ™®é€šå®¶åº­çš„é€‚è€åŒ–æ”¹é€ åŸåˆ™ä¸ä½æˆæœ¬ã€å¯åŠ¨æ‰‹çš„å®æ–½å»ºè®®ï¼Œå¸®åŠ©æå‡å±…å®¶å®‰å…¨æ€§ä¸ä¾¿åˆ©æ€§ã€‚

## ä¸€ã€å®‰å…¨ä¼˜å…ˆï¼šé¢„é˜²è·Œå€’ä¸è¯¯æ“ä½œ
- **é˜²æ»‘é˜²ç»Š**ï¼šåœ¨åœ°é¢é“ºè®¾é˜²æ»‘å«ï¼Œå°¤å…¶æµ´å®¤ã€å¨æˆ¿ç­‰æ¹¿æ»‘åŒºåŸŸï¼›å›ºå®šåœ°æ¯¯è¾¹ç¼˜ï¼Œé¿å…å·è¾¹ç»Šå€’ï¼›æ•´ç†ç”µçº¿ï¼Œé˜²æ­¢ç¼ ç»•æˆ–ç»Šè„šã€‚
- **é¿å…å°–é”è®¾è®¡**ï¼šå®¶å…·è¾¹è§’åšå€’åœ†å¤„ç†ï¼Œæˆ–ä½¿ç”¨é˜²æ’è§’ä¿æŠ¤ï¼›ç§»é™¤æˆ–é®ç›–å°–é”çªå‡ºç‰©ã€‚
- **ç¨³å®šæ”¯æ’‘**ï¼šä¸ºå®¶å…·æ·»åŠ é˜²æ»‘è„šå«ï¼Œç¡®ä¿ç«™ç«‹æ—¶ç¨³å®šï¼›å¸¸ç”¨ç‰©å“æ”¾ç½®äºæ˜“å–ä½ç½®ï¼Œå‡å°‘ç™»é«˜æˆ–å¼¯è…°ã€‚

## äºŒã€æ„Ÿå®˜å‹å¥½ï¼šå¼ºåŒ–è§†è§‰ã€å¬è§‰ä¸è§¦è§‰æç¤º
- **è§†è§‰å¢å¼º**ï¼šé‡‡ç”¨å¤§å·æ— è¡¬çº¿å­—ä½“æ ‡æ³¨å¼€å…³ã€æ ‡ç­¾ï¼›æé«˜ç…§æ˜äº®åº¦ï¼Œé¿å…çœ©å…‰ï¼›å…³é”®ä¿¡æ¯ï¼ˆå¦‚åº”æ€¥ç”µè¯ï¼‰ç½®äºé†’ç›®ä½ç½®ã€‚
- **å¬è§‰è¾…åŠ©**ï¼šé™ä½å®¶ç”µå™ªéŸ³ï¼Œè®¾ç½®æ¸…æ™°æ“ä½œæç¤ºéŸ³ï¼›å¿…è¦æ—¶ä»¥æŒ¯åŠ¨æˆ–ç¯å…‰è¡¥å……æé†’ã€‚
- **è§¦è§‰ä¼˜åŒ–**ï¼šé€‰æ‹©è¡¨é¢æ¸©æš–ã€æè´¨æŸ”è½¯çš„å®¶å±…ç”¨å“ï¼›æ§åˆ¶æŒ‰é”®é—´è·é€‚ä¸­ï¼Œé¿å…è¯¯è§¦ã€‚

## ä¸‰ã€ä½“èƒ½æ”¯æŒï¼šå‡å°‘èº«ä½“è´Ÿæ‹…
- **ç®€åŒ–æ“ä½œ**ï¼šé€‰æ‹©å•æ‰‹å¯æ“ä½œçš„ç‰©å“ï¼Œé¿å…å¤æ‚æµç¨‹ï¼›å¸¸ç”¨å·¥å…·ï¼ˆå¦‚é¥æ§å™¨ã€æ°´é¾™å¤´ï¼‰åº”è½»ä¾¿çœåŠ›ã€‚
- **ç©ºé—´é€‚é…**ï¼šç¡®ä¿é€šé“å®½æ•ï¼Œä¾¿äºè½®æ¤…æˆ–åŠ©è¡Œå™¨é€šè¿‡ï¼›å‡å°‘è½¬èº«ã€å¼¯è…°åŠ¨ä½œï¼Œå¦‚ä½¿ç”¨å¯è°ƒèŠ‚é«˜åº¦çš„å®¶å…·ã€‚

## å››ã€è®¤çŸ¥ç®€åŒ–ï¼šæå‡æ˜“ç”¨æ€§ä¸ç†è§£åº¦
- **æµç¨‹ç›´è§‚åŒ–**ï¼šå®¶ç”µæ“ä½œæ­¥éª¤æ§åˆ¶åœ¨ä¸‰æ­¥ä»¥å†…ï¼›ä½¿ç”¨å›¾ç¤ºä»£æ›¿æ–‡å­—è¯´æ˜ã€‚
- **åé¦ˆæ˜ç¡®**ï¼šæ“ä½œæˆåŠŸåæä¾›å£°éŸ³æˆ–ç¯å…‰åé¦ˆï¼Œå¸®åŠ©ç¡®è®¤ï¼›è®¾ç½®å¼‚å¸¸è­¦æŠ¥ï¼ˆå¦‚ç‡ƒæ°”æ³„æ¼ç›‘æµ‹ï¼‰ã€‚

## äº”ã€ä½æˆæœ¬æ”¹é€ å»ºè®®
- **DIYè°ƒæ•´**ï¼šç”¨é˜²æ»‘è´´æ”¹é€ åœ°æ¿ï¼›å®‰è£…æ„Ÿåº”å°å¤œç¯ï¼›ç”¨æ ‡ç­¾æœºæ ‡æ³¨è¯å“å’Œå¼€å…³ã€‚
- **ä¼˜å…ˆæ”¹é€ åŒº**ï¼šèšç„¦æµ´å®¤ã€å¨æˆ¿ã€å§å®¤ç­‰é«˜é¢‘åŒºåŸŸï¼Œé€šè¿‡å°æŠ•å…¥å®ç°å¤§æ”¹å–„ã€‚

é€‚è€å®œå±…æ”¹é€ çš„æ ¸å¿ƒæ˜¯â€œä»¥äººä¸ºä¸­å¿ƒâ€ï¼Œé€šè¿‡ç»†å¾®è°ƒæ•´æ˜¾è‘—æå‡ç”Ÿæ´»å“è´¨ã€‚å®šæœŸæ£€æŸ¥å®¶å±…ç¯å¢ƒï¼Œç»“åˆè€å¹´äººå®é™…éœ€æ±‚çµæ´»ä¼˜åŒ–ï¼Œè®©å®¶æˆä¸ºå®‰å…¨ã€èˆ’é€‚ã€æ¸©æš–çš„æ¸¯æ¹¾ã€‚

---
*æœ¬æŒ‡å—åŸºäºã€Šå®¶å±…äº§å“é€‚è€åŒ–è®¾è®¡æŒ‡å—ã€‹æç‚¼ï¼Œé‡ç‚¹èšç„¦ä½æˆæœ¬ã€å¯åŠ¨æ‰‹çš„è§£å†³æ–¹æ¡ˆï¼ŒåŠ©åŠ›å®ç°å±…å®¶é€‚è€åŒ–ã€‚*

# ä»»åŠ¡è¦æ±‚

ä½ éœ€è¦æ ¹æ®"å®¶å±…äº§å“é€‚è€åŒ–è®¾è®¡æŒ‡å—"å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œ
å¦‚æœç”¨æˆ·çš„é—®é¢˜ä¸æŒ‡å—ä¸ç›¸å…³ï¼Œåˆ™æ‹’ç»å›ç­”å¹¶æé†’ç”¨æˆ·ï¼Œ
ç”¨æˆ·çš„é—®é¢˜æ˜¯ï¼š
"""

markdown_text = \
"""
# ğŸ  é€‚è€å®œå±…è®¾è®¡å¸ˆ

æ¬¢è¿ä½¿ç”¨ï¼æœ¬å·¥å…·å¸®åŠ©æ‚¨ï¼ˆæˆ–æ‚¨çš„çˆ¶æ¯ï¼‰ä¸»åŠ¨å‘ç°å®¶ä¸­æ½œåœ¨çš„å®‰å…¨éšæ‚£ï¼ˆå¦‚åœ°æ¯¯å·è¾¹ã€æµ´å®¤æ¹¿æ»‘ã€ç”µçº¿æ‚ä¹±ï¼‰ï¼Œå¹¶æä¾›**ä½æˆæœ¬ã€å¯åŠ¨æ‰‹**çš„é€‚è€åŒ–æ”¹é€ å»ºè®®ã€‚
"""

markdown_about = \
"""
### âœ¨ åŠŸèƒ½ç‰¹è‰²
* **æ™ºèƒ½æ’æŸ¥éšæ‚£ï¼š** AI è‡ªåŠ¨è¯†åˆ«ç…§ç‰‡ä¸­çš„è·Œå€’ã€ç«ç¾ç­‰é£é™©ã€‚
* **ä¸“ä¸šæ”¹é€ å»ºè®®ï¼š** æä¾› 1-3 æ¡æœ€å…³é”®ã€æœ€å®ç”¨çš„æ–‡å­—å»ºè®®ã€‚
* **ç›´è§‚æ•ˆæœé¢„è§ˆï¼š** ç”Ÿæˆä¸€å¼ â€œæ”¹é€ åâ€çš„ç¤ºæ„å›¾ï¼Œè®©æ‚¨ä¸€çœ‹å°±æ‡‚ã€‚

### ğŸ“ å¦‚ä½•ä½¿ç”¨
1.  **æ‹æ‘„ç…§ç‰‡ï¼š** ç‚¹å‡»ä¸‹æ–¹çš„â€œæ‹æ‘„æˆ–ä¸Šä¼ ç…§ç‰‡â€æ¡†ï¼Œæ‹ä¸€å¼ æ‚¨å®¶ä¸­çš„ï¼ˆå¦‚ **æµ´å®¤ã€å¨æˆ¿ã€å§å®¤**ï¼‰çš„ç…§ç‰‡ã€‚
2.  **ä¸€é”®è¯„ä¼°ï¼š** ç‚¹å‡» **â€œä¸€é”®è¯„ä¼°â€** æŒ‰é’®ã€‚
3.  **è·å–æŠ¥å‘Šï¼š** AI å°†é¦–å…ˆç”Ÿæˆâ€œè¯„ä¼°å»ºè®®â€ï¼ˆæ–‡å­—ï¼‰ï¼Œç¨ç­‰ç‰‡åˆ»åï¼Œå°†ç”Ÿæˆâ€œæ”¹é€ åç¤ºæ„å›¾â€ï¼ˆå›¾ç‰‡ï¼‰ã€‚
"""

# ------------------ å·¥å…· ------------------
def upload_image2z(pil_img: Image.Image) -> str:
    buf = io.BytesIO()
    pil_img.convert('RGB').save(buf, format='JPEG', quality=90)
    buf.seek(0)
    rsp = requests.post(Z_API, files={'file': ('u.jpg', buf, 'image/jpeg')},
                        data={'uid': Z_TOKEN, 'fileName': 'u.jpg'}, timeout=30)
    rsp.raise_for_status()
    return rsp.json()['url']

def edit_image(url: str, *, edit_prompt: str) -> Image.Image:
    """PIL + ç¼–è¾‘æç¤ºè¯ â†’ DashScope qwen-image-edit-plus â†’ PIL"""
    # url = upload_image2z(pil_img)   # åŸå›¾å…¬ç½‘ url
    rsp = requests.post(
        "https://dashscope.aliyuncs.com/api/v1/services/aigc/multimodal-generation/generation",
        headers={"Authorization": f"Bearer {DS_KEY}", "Content-Type": "application/json"},
        json={
            "model": "qwen-image-edit-plus",
            "input": {
                "messages": [{
                    "role": "user",
                    "content": [{"image": url},
                                {"text": edit_prompt}]
                }]
            },
            "parameters": {"n": 1, "watermark": False}
        },
        timeout=60)
    rsp.raise_for_status()
    new_url = rsp.json()['output']['choices'][0]['message']['content'][0]['image']
    return Image.open(io.BytesIO(requests.get(new_url, timeout=30).content))

# ------------------ æµå¼å»ºè®® ------------------
def stream_advise(image_url: str):
    client = OpenAI(base_url=MS_API_URL, api_key=MS_TOKEN)
    for chk in client.chat.completions.create(
            model='Qwen/Qwen3-VL-235B-A22B-Instruct',
            messages=[{"role": "user",
                       "content": [{"type": "text", "text": PROMPT},
                                   {"type": "image_url", "image_url": {"url": image_url}}]}],
            stream=True):
        if chk.choices[0].delta.content:
            yield chk.choices[0].delta.content

# ----------- Tab2 é€»è¾‘ -----------
client = OpenAI(
    base_url='https://api-inference.modelscope.cn/v1',
    api_key = os.getenv('MS_TOKEN'),
)

def stream_qwen_response(user_message: str, messages: list) -> Iterator[list]:
    extra_body = {"enable_thinking": True}
    resp = client.chat.completions.create(
        model='Qwen/Qwen3-32B',
        messages=[{"role": "user", "content": PROMPT_ASK + user_message}],
        stream=True,
        extra_body=extra_body
    )

    thought_buffer = ""
    response_buffer = ""
    thinking_complete = False

    # åˆå§‹â€œæ€è€ƒä¸­â€å ä½
    messages.append(
        ChatMessage(
            role="assistant",
            content="",
            metadata={"title": "â³Thinking: *The thoughts produced by the Qwen3 model are experimental"}
        )
    )
    yield messages

    for chunk in resp:
        delta = chunk.choices[0].delta
        thinking_chunk = delta.reasoning_content
        answer_chunk = delta.content

        # 1. è¿˜åœ¨æ€è€ƒ
        if thinking_chunk is not None and thinking_chunk != "":
            thought_buffer += thinking_chunk
            messages[-1] = ChatMessage(
                role="assistant",
                content=thought_buffer,
                metadata={"title": "â³Thinking: *The thoughts produced by the Qwen3 model are experimental"}
            )
            yield messages
            continue

        # 2. å¼€å§‹/ç»§ç»­å›ç­”
        if answer_chunk is not None and answer_chunk != "":
            if not thinking_complete:
                # æ ‡è®°æ€è€ƒç»“æŸï¼ŒåŒæ—¶æŠŠç¬¬ä¸€ä¸ª answer_chunk ä¹Ÿæ”¶è¿› buffer
                thinking_complete = True
                response_buffer += answer_chunk
                messages[-1] = ChatMessage(
                    role="assistant",
                    content=thought_buffer,
                    metadata={"title": "âœ… Thinking Complete"}
                )
                # æ–°å»ºä¸€æ¡æ¶ˆæ¯ä¸“é—¨å±•ç¤ºå›ç­”
                messages.append(
                    ChatMessage(role="assistant", content=response_buffer)
                )
            else:
                # ç»§ç»­ç´¯åŠ å›ç­”
                response_buffer += answer_chunk
                messages[-1] = ChatMessage(role="assistant", content=response_buffer)
            yield messages


def user_message(user_msg: str, messages: list):
    messages.append(ChatMessage(role="user", content=user_msg))
    return "", messages


# ------------------------------------------------------------------
# Tab3 é€»è¾‘ï¼šPDF å±•ç¤º
# ------------------------------------------------------------------

def pdf_to_images(pdf_path=PDF_PATH, dpi=120):
    """å°† PDF é€é¡µè½¬ PIL å›¾ç‰‡ï¼Œä¾› Gradio Gallery å±•ç¤º"""
    if not os.path.isfile(pdf_path):
        return [Image.new("RGB", (400, 600), color="gray")]
    doc = fitz.open(pdf_path)
    images = []
    for page in doc:
        pix = page.get_pixmap(dpi=dpi)
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
        images.append(img)
    doc.close()
    return images if images else [Image.new("RGB", (400, 600), color="gray")]

# ------------------ ä¸»é€»è¾‘ ------------------
_cache = {}

def ai_advise(image):
    if image is None:
        yield 'è¯·å…ˆä¸Šä¼ ä¸€å¼ ç…§ç‰‡', None
        return

    # 1. å…ˆä¸Šä¼ åŸå›¾ï¼Œæ‹¿åˆ° url å¤‡ç”¨
    key = hashlib.md5(image.tobytes()).hexdigest()
    url = _cache.get(key)
    if not url:
        try:
            url = upload_image2z(image)
            _cache[key] = url
        except Exception as e:
            yield f'ï¼ˆå›¾ç‰‡ä¸Šä¼ å¤±è´¥ï¼š{e}ï¼‰', None
            return

    # 2. æµå¼è¾“å‡ºæ–‡å­—å»ºè®®
    buffer = ''
    for piece in stream_advise(url):
        buffer += piece
        yield buffer, None          # å›¾æš‚æ—¶ç»™ Noneï¼Œå‰ç«¯åªæ›´æ–°æ–‡å­—

    # 3. æµç»“æŸï¼Œç”¨æœ€ç»ˆæ–‡å­—ç”Ÿæˆæ”¹é€ å›¾
    try:
        after = edit_image(url, edit_prompt=buffer)
    except Exception as e:
        yield f'{buffer}\n\nï¼ˆæ”¹é€ å›¾ç”Ÿæˆå¤±è´¥ï¼š{e}ï¼‰', None
        return

    # 4. ä¸€æ¬¡æ€§æŠŠæœ€ç»ˆæ–‡å­—+æ”¹é€ å›¾æ¨å‡ºå»
    yield buffer, after

# ------------------ Gradio UI ------------------
with gr.Blocks(title='é¢å±…æ…§è§†') as demo:
    gr.Markdown(markdown_text) # 'ğŸ  é€‚è€å®œå±…è®¾è®¡å¸ˆ Â· è®© AI å¸®çˆ¸å¦ˆæŠŠå®¶å˜å¾—æ›´å®‰å…¨')
    with gr.Tab('ğŸ“¸ ç¯å¢ƒè¯„ä¼°'):
        with gr.Row():
            with gr.Column():
                img_in = gr.Image(label='1. æ‹æ‘„æˆ–ä¸Šä¼ ç…§ç‰‡', type='pil')
                btn    = gr.Button('ä¸€é”®è¯„ä¼°', elem_classes='gr-button-primary')
                # â‘  æ–°å¢ç¤ºä¾‹å›¾ï¼Œæ”¯æŒä»»æ„å¯å…¬å¼€è®¿é—®çš„ URL
                gr.Examples(
                    examples=[
                        "https://pic7.fukit.cn/autoupload/Rw6YVAKeYl4ryDjv52L9NA/20251103/DnUK/1000X750/03.jpg",
                        "https://pic7.fukit.cn/autoupload/Rw6YVAKeYl4ryDjv52L9NA/20251103/5Aiu/780X438/01.jpg",
                        "https://pic7.fukit.cn/autoupload/Rw6YVAKeYl4ryDjv52L9NA/20251103/9UDn/710X400/08.jpg",
                        "https://pic7.fukit.cn/autoupload/Rw6YVAKeYl4ryDjv52L9NA/20251103/Vhu7/1000X750/02.jpg",
                        "https://pic7.fukit.cn/autoupload/Rw6YVAKeYl4ryDjv52L9NA/20251103/7CEm/780X438/04.jpg",
                        # "https://pic7.fukit.cn/autoupload/Rw6YVAKeYl4ryDjv52L9NA/20251103/YXz8/780X438/05.jpg"
                        # éœ€è¦å†åŠ åˆ«çš„å›¾ï¼Œç»§ç»­å¾€åˆ—è¡¨é‡Œå¡« URL å³å¯
                    ],
                    inputs=img_in,
                    label="ğŸ“· å¿«é€Ÿä½“éªŒï¼ˆç‚¹å‡»å³å¯åŠ è½½ï¼‰"
                )
            with gr.Column():
                adv_out = gr.Textbox(label='2. AI è¯„ä¼°å»ºè®®', lines=4, interactive=False)
                img_out = gr.Image(label='3. AI æ”¹é€ åç¤ºæ„å›¾', type='pil')
        btn.click(ai_advise, inputs=img_in, outputs=[adv_out, img_out])

    with gr.Tab("ğŸ’¬ è¿›ä¸€æ­¥å’¨è¯¢"):

        chatbot = gr.Chatbot(type="messages", label="é€‚è€è®¾è®¡é—®ç­”åŠ©æ‰‹", render_markdown=True)
        input_box = gr.Textbox(lines=1, label="è¯·è¾“å…¥é—®é¢˜å¹¶æŒ‰å›è½¦é”®", placeholder="ä¾‹å¦‚ï¼šå•æ‰€çš„è£…ä¿®éœ€è¦æ³¨æ„ä»€ä¹ˆ")
        msg_store = gr.State("")

        input_box.submit(
            lambda msg: (msg, msg, ""),
            inputs=[input_box],
            outputs=[msg_store, input_box, input_box],
            queue=False
        ).then(
            user_message,
            inputs=[msg_store, chatbot],
            outputs=[input_box, chatbot],
            queue=False
        ).then(
            stream_qwen_response,
            inputs=[msg_store, chatbot],
            outputs=chatbot
        )

        examples = gr.Examples(
        examples=[
            "å•æ‰€çš„è£…ä¿®éœ€è¦æ³¨æ„ä»€ä¹ˆ",
            "å¨æˆ¿æœ‰å“ªäº›å±é™©éœ€è¦æ³¨æ„",
            "å¦‚ä½•å¢åŠ å®¶å…·ç¨³å®šæ€§"
        ],
        inputs=input_box,
        label="å¿«é€Ÿæé—®"
        )

    with gr.Tab("ğŸ“– å‚è€ƒä¹¦ç±"):
        gallery = gr.Gallery(label="PDF é¢„è§ˆ", columns=2, height=700)
        demo.load(fn=pdf_to_images, inputs=None, outputs=gallery)

    with gr.Tab("âš™ï¸ åº”ç”¨è¯´æ˜"):
        with gr.Row():
            with gr.Column(scale=1):
                gr.Image("./show.png",label="æŠ€æœ¯å®ç°æµç¨‹")
            with gr.Column(scale=2):
                gr.Markdown(markdown_about)
                gr.Image("./compare.png",label="å®ç°æ•ˆæœ")

demo.queue().launch(server_name='0.0.0.0', debug=True, show_api=False)
