# -*- coding: utf-8 -*-
"""
é¢å±…æ…§è§† â€“ ç²¾ç®€ä¸‰æ ç‰ˆï¼ˆModelScope + DashScope å›¾åƒç¼–è¾‘ï¼‰
"""
import os, io, hashlib, requests, gradio as gr
from PIL import Image
from openai import OpenAI
import fitz  # PyMuPDF
import random



# ------------------ é…ç½® ------------------
Z_TOKEN    = os.getenv('Z_TOKEN') or 'hellocgc@qq.com'
Z_API      = "https://playground.z.wiki/img/api/upload"
MS_TOKEN   = os.getenv('MS_TOKEN') or "ms-da2c260d-9d0a-48c7-9624-53cd424d8108"
MS_API_URL = "https://api-inference.modelscope.cn/v1"
DS_KEY     = os.getenv('DASHSCOPE_API_KEY') or "sk-55180135971c4d909f780892f2c8f8e1"
PDF_PATH = r"/content/P020240613034653.pdf"  # è¯·æ¢æˆçœŸå®è·¯å¾„

PROMPT = (
    "ä½ éœ€è¦ä»é€‚è€åŒ–æ”¹é€ çš„è§’åº¦å‡ºå‘ï¼Œæå‡º1-3ä¸ªæœ€é‡è¦çš„åˆç†å»ºè®®ï¼Œ\n"
    "è¦æ±‚ï¼š\n1. ä»…é™å®šä½ çœ‹åˆ°çš„ç”»é¢ï¼›\n"
    "2. ä½¿ç”¨ç›¸å¯¹ä½ç½®æè¿°ï¼Œå‹¿ç»™å‡ºç»å¯¹å°ºå¯¸ï¼›\n"
    "3. æ ¼å¼ä¸ºâ€œåºå·.æ”¹é€ å»ºè®®â€ã€‚"
)

EDIT_PROMPT = "æŠŠæˆ¿é—´æ”¹é€ æˆé€‚åˆè€äººå±…ä½çš„å®‰å…¨ç¯å¢ƒï¼Œä¿ç•™åŸç»“æ„ï¼Œä»…æ›¿æ¢å®¶å…·/è½¯è£…"

# ------------------ å·¥å…· ------------------
def upload_image2z(pil_img: Image.Image) -> str:
    buf = io.BytesIO()
    pil_img.convert('RGB').save(buf, format='JPEG', quality=90)
    buf.seek(0)
    rsp = requests.post(Z_API, files={'file': ('u.jpg', buf, 'image/jpeg')},
                        data={'uid': Z_TOKEN, 'fileName': 'u.jpg'}, timeout=30)
    rsp.raise_for_status()
    return rsp.json()['url']

def edit_image(url: str, *, edit_prompt: str) -> Image.Image:
    """PIL + ç¼–è¾‘æç¤ºè¯ â†’ DashScope qwen-image-edit-plus â†’ PIL"""
    # url = upload_image2z(pil_img)   # åŸå›¾å…¬ç½‘ url
    rsp = requests.post(
        "https://dashscope.aliyuncs.com/api/v1/services/aigc/multimodal-generation/generation",
        headers={"Authorization": f"Bearer {DS_KEY}", "Content-Type": "application/json"},
        json={
            "model": "qwen-image-edit-plus",
            "input": {
                "messages": [{
                    "role": "user",
                    "content": [{"image": url},
                                {"text": edit_prompt}]
                }]
            },
            "parameters": {"n": 1, "watermark": False}
        },
        timeout=60)
    rsp.raise_for_status()
    new_url = rsp.json()['output']['choices'][0]['message']['content'][0]['image']
    return Image.open(io.BytesIO(requests.get(new_url, timeout=30).content))

# ------------------ æµå¼å»ºè®® ------------------
def stream_advise(image_url: str):
    client = OpenAI(base_url=MS_API_URL, api_key=MS_TOKEN)
    for chk in client.chat.completions.create(
            model='Qwen/Qwen3-VL-235B-A22B-Instruct',
            messages=[{"role": "user",
                       "content": [{"type": "text", "text": PROMPT},
                                   {"type": "image_url", "image_url": {"url": image_url}}]}],
            stream=True):
        if chk.choices[0].delta.content:
            yield chk.choices[0].delta.content

# ----------- Tab2 é€»è¾‘ -----------
def fake_chat(history, user_msg):
    history = history or []
    replies = [
        "æ‚¨å¯ä»¥è€ƒè™‘å®‰è£…æ„Ÿåº”å¤œç¯ï¼Œå‡å°‘èµ·å¤œè·Œå€’é£é™©ã€‚",
        "å®¶å…·åœ†è§’å¤„ç†æˆ–åŠ è£…é˜²æ’æ¡ï¼Œä¹Ÿæ˜¯ä½æˆæœ¬çš„å¥½æ–¹æ³•ã€‚",
        "å¦‚éœ€è¿›ä¸€æ­¥å¸®åŠ©ï¼Œå¯å’¨è¯¢æœ¬åœ°ç¤¾åŒºå…»è€æœåŠ¡ä¸­å¿ƒã€‚",
    ]
    history.append([user_msg, random.choice(replies)])
    return history
	
# ------------------------------------------------------------------
# Tab3 é€»è¾‘ï¼šPDF å±•ç¤º
# ------------------------------------------------------------------

def pdf_to_images(pdf_path=PDF_PATH, dpi=120):
    """å°† PDF é€é¡µè½¬ PIL å›¾ç‰‡ï¼Œä¾› Gradio Gallery å±•ç¤º"""
    if not os.path.isfile(pdf_path):
        return [Image.new("RGB", (400, 600), color="gray")]
    doc = fitz.open(pdf_path)
    images = []
    for page in doc:
        pix = page.get_pixmap(dpi=dpi)
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
        images.append(img)
    doc.close()
    return images if images else [Image.new("RGB", (400, 600), color="gray")]

# ------------------ ä¸»é€»è¾‘ ------------------
_cache = {}

def ai_advise(image):
    if image is None:
        yield 'è¯·å…ˆä¸Šä¼ ä¸€å¼ ç…§ç‰‡', None
        return

    # 1. å…ˆä¸Šä¼ åŸå›¾ï¼Œæ‹¿åˆ° url å¤‡ç”¨
    key = hashlib.md5(image.tobytes()).hexdigest()
    url = _cache.get(key)
    if not url:
        try:
            url = image_url # upload_image2z(image)
            _cache[key] = url
        except Exception as e:
            yield f'ï¼ˆå›¾ç‰‡ä¸Šä¼ å¤±è´¥ï¼š{e}ï¼‰', None
            return

    # 2. æµå¼è¾“å‡ºæ–‡å­—å»ºè®®
    buffer = ''
    for piece in stream_advise(url):
        buffer += piece
        yield buffer, None          # å›¾æš‚æ—¶ç»™ Noneï¼Œå‰ç«¯åªæ›´æ–°æ–‡å­—

    # 3. æµç»“æŸï¼Œç”¨æœ€ç»ˆæ–‡å­—ç”Ÿæˆæ”¹é€ å›¾
    try:
        after = edit_image(url, edit_prompt=buffer)
    except Exception as e:
        yield f'{buffer}\n\nï¼ˆæ”¹é€ å›¾ç”Ÿæˆå¤±è´¥ï¼š{e}ï¼‰', None
        return

    # 4. ä¸€æ¬¡æ€§æŠŠæœ€ç»ˆæ–‡å­—+æ”¹é€ å›¾æ¨å‡ºå»
    yield buffer, after

# ------------------ Gradio UI ------------------
with gr.Blocks(title='é¢å±…æ…§è§†') as demo:
    gr.Markdown('ğŸ  é¢å±…æ…§è§† Â· è®© AI å¸®çˆ¸å¦ˆæŠŠå®¶å˜å¾—æ›´å®‰å…¨')
    with gr.Tab('ğŸ“¸ ç¯å¢ƒè¯„ä¼°'):
        with gr.Row():
            img_in = gr.Image(label='1. æ‹æ‘„æˆ–ä¸Šä¼ ç…§ç‰‡', type='pil')
            with gr.Column():
                adv_out = gr.Textbox(label='2. AI è¯„ä¼°å»ºè®®', lines=4, interactive=False)
                img_out = gr.Image(label='3. AI æ”¹é€ åç¤ºæ„å›¾', type='pil')
        btn = gr.Button('ä¸€é”®è¯„ä¼°', elem_classes='gr-button-primary')
        btn.click(ai_advise, inputs=img_in, outputs=[adv_out, img_out])

    with gr.Tab("ğŸ’¬ è¿›ä¸€æ­¥å’¨è¯¢"):
        chatbot = gr.Chatbot(label="é€‚è€æ”¹é€ å°åŠ©æ‰‹", elem_classes="gr-chatbot", height=400)
        msg = gr.Textbox(label="è¾“å…¥æ‚¨çš„é—®é¢˜", placeholder="ä¾‹å¦‚ï¼šæµ´å®¤é˜²æ»‘è¿˜æœ‰å“ªäº›ä¾¿å®œæ–¹æ¡ˆï¼Ÿ")
        send = gr.Button("å‘é€", elem_classes="gr-button-primary")
        send.click(fake_chat, inputs=[chatbot, msg], outputs=chatbot)
        msg.submit(fake_chat, inputs=[chatbot, msg], outputs=chatbot)

    with gr.Tab("ğŸ“– å‚è€ƒä¹¦ç±"):
        gallery = gr.Gallery(label="PDF é¢„è§ˆ", columns=2, height=700)
        demo.load(fn=pdf_to_images, inputs=None, outputs=gallery)

demo.queue().launch(server_name='0.0.0.0', debug=True, show_api=False)
